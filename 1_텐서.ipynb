{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aadf2a64-cd0e-4010-b747-f612a09c5da6",
   "metadata": {},
   "source": [
    "# 텐서(TENSOR)\n",
    "- 텐서는 배열이나 행렬과 매우 유사한 특수한 자료구조\n",
    "- 파이토치에서는 텐서를 사용하여 모델의 입력과 출력, 그리고 모델의 매개변수들을 부호화\n",
    "- 텐서는 GPU나 다른 하드웨어 가속기 실행할 수 있다는 점 제외하면 넘파이의 ndarray와 유사\n",
    "- 텐서와 넘파이 배열은 종종 동일한 내부 메모릴르 공유할 수 있어 데이터를 복사할 필요 없다\n",
    "- 텐서는 자동미분에 최적하되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ce71478-d973-4d0e-b315-a29cfafbc4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f6eae8-9c3d-44a0-aeb1-ead017eb220c",
   "metadata": {},
   "source": [
    "## 텐서 초기화\n",
    "텐서는 여러가지 방법으로 초기화할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e267d4d-a274-45c9-8413-04d85c47babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1,2],[3,4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9def9b4-2460-42aa-943f-17d742d07f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 넘파이 배열로 생성\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "620774de-08f2-4b13-ab0f-9f6d43aaa1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor : \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Ones Tensor : \n",
      " tensor([[0.1425, 0.4870],\n",
      "        [0.1187, 0.3508]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 다른 텐서로부터 생성하기\n",
    "# 재정의하지 않으면, 인자로 주어진 텐서의 속성(모양, 자료형) 유지\n",
    "\n",
    "x_ones = torch.ones_like(x_data) # x_data의 속성을 유지\n",
    "print(f'Ones Tensor : \\n {x_ones} \\n')\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype = torch.float) # x_data의 속성을 덮어씀\n",
    "print(f'Ones Tensor : \\n {x_rand} \\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01dde8ec-14dc-48d1-b1a3-e76ec31d46a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor : \n",
      " tensor([[0.4369, 0.3658, 0.8564],\n",
      "        [0.0800, 0.2873, 0.2833]]) \n",
      "\n",
      "Random Tensor : \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Random Tensor : \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# random or 상수(constant) 값을 사용하기\n",
    "## shape은 텐서의 차원을 나타내는 튜플로 아래 함수들에서는 출력 텐서의 차원을 결정\n",
    "\n",
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f'Random Tensor : \\n {rand_tensor} \\n')\n",
    "print(f'Random Tensor : \\n {ones_tensor} \\n')\n",
    "print(f'Random Tensor : \\n {zeros_tensor}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0ee4cd-4aa2-4b3f-9707-99c3c0bc81e8",
   "metadata": {},
   "source": [
    "## 텐서의 속성\n",
    "텐서의 속성은 텐서의 모양, 자료형 및 어느 장치에 저장되는지를 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "994bf7ce-8fa4-4c05-a74f-cf64eade1760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Tensor : \n",
      " torch.Size([3, 4]) \n",
      "\n",
      "Datatype of tensor : \n",
      " torch.float32 \n",
      "\n",
      "Device tensor is stored on : \n",
      " cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f'Shape of Tensor : \\n {tensor.shape} \\n')\n",
    "print(f'Datatype of tensor : \\n {tensor.dtype} \\n')\n",
    "print(f'Device tensor is stored on : \\n {tensor.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe7dd18-d02e-4628-be54-29ff7c274990",
   "metadata": {},
   "source": [
    "# 텐서 연산(Operation)\n",
    "- 전치, 인덱싱, 슬라이싱, 수학계산, 선형대수, 임의 샘플링 등\n",
    "- 각 여산들은 GPU에서 실행 가능\n",
    "- 기본적으로 텐서는 CPU에 생성\n",
    "- .to 메소들르 사용하면 GPU로 텐서를 명시적으로 이동 가능\n",
    "- 장치들 간에 큰 텐서들을 복사하는 것은 시간과 메모리 측면에서 비용이 많이 든다는 것을 기억!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc475105-fc7d-4ede-8fbd-962c18d36cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU가 존재하면 텐서를 이동\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tnesor.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7155ebf-a953-4527-ae4d-a046abbedd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First row: tensor([1., 1., 1., 1.])\n",
      "Last row: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# numpy식의 표준 인덱싱과 슬라이싱 \n",
    "\n",
    "tensor = torch.ones(4,4)\n",
    "print(f'First row: {tensor[0]}')\n",
    "print(f'First row: {tensor[:,0]}')\n",
    "print(f'Last row: {tensor[...,-1]}')\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "295826cd-33aa-48c7-950c-0a5baeaf3a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[:,0].dim(), tensor[...,0].dim()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3bf2ad-ff4d-43cc-b206-3a9ebe97f612",
   "metadata": {},
   "source": [
    "텐서합치기 torch.cat을 사용하여 주어진 차원에 따라 일려느이 텐서르 연결할 수 있습니다. torch.cat과 미묘하게 다른 또 다른 텐서 결합 연산인 torch.stack도 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54e44ede-4a77-471f-ab99-081fd87882a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ebcae9d-15c7-4427-a63c-dc5f5832eaef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 산술 연산\n",
    "\n",
    "# 두 텐서 간의 행렬 곱을 계산 , y1,y2,y3은 모두 같은 값을 갖느다\n",
    "# tensor.T 는 텐서의 전치를 반환\n",
    "\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "# 요소별 곱을 계산, z1,z2,z3는 모두 같은 값을 갖는다.\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out= z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62e11ac-bb4a-4b1a-94e6-035eb95dabca",
   "metadata": {},
   "source": [
    "단일-요소 텐서  \n",
    "텐서의 모든 값을 하나로 집계하여 요소가 하나인 텐서의 경우, item()을 사요하여 python숫자값으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ded28b3-43cd-480a-b758-15e4bb0e466b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870f7b46-83bf-4b14-9baa-e1313880fa7e",
   "metadata": {},
   "source": [
    "바꿔치기 연산  \n",
    "연산결과를 피연산자에 저장하는 연산을 바꿔치기 연산이라고 부른다.  \n",
    "_ 접미사를 갖는다. 예를 들어 : x_copy_(y) 나 x.t_()는 x를 변경한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d759514-106d-41b5-afd3-741c2f4f7a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{tensor} \\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5880821-52a6-47ef-9dbf-677dcd00aa58",
   "metadata": {},
   "source": [
    "** 참고 **  \n",
    "\n",
    "바꿔치기 연산은 메로미를 일부 절약하지만, 기록이 즉시 삭제되어 도함수 계산에 문제가 발생할 수 있다.   \n",
    "따라서, 사용을 권장하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d764588-3a91-4605-9ab2-fcc963a671bd",
   "metadata": {},
   "source": [
    "# Numpy 변환(Bridge)\n",
    "CPU 상의 텐서와 넘파이 배열은 메모리 공간을 공유하기 때문에, 하나를 변경하면 다른 하나도 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c589f342-8c48-464f-bc4a-bd70ade13221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f't: {t}')\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4419055-3011-4c9a-bf58-02834085d868",
   "metadata": {},
   "source": [
    "### numpy 배열을 텐서로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d9f1c69-2850-4a68-bc63-cbdaffda6e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b57875f-21b8-4c71-be84-eeca381b1e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n,1, out = n)\n",
    "print(f't: {t}')\n",
    "print(f'n: {n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6444d7-3444-46cc-ac0e-cc3d3559bc63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
