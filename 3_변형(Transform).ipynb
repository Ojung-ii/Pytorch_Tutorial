{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6094e503-0561-4b30-b46b-c477f8ae9bc6",
   "metadata": {},
   "source": [
    "# 변형(Transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad92528-b842-4121-be5b-954457d0da5b",
   "metadata": {},
   "source": [
    "데이터가 항상 머신러닝 알고리즘 학습에 필요한 최종 처리가 된 형태를 제공하지 않는다.  \n",
    "변형을 해서 데이터를 조작하고 학습에 적합하게 만든다.  \n",
    "모든 torchvision 데이터셋들은 변형로직을 갖는, 호출 가능한 객체(callable)를 받는 매개변수 두개(특징(feature)을 변경하기 위한 transform과 정답을 변경하기 위한 target_transform)를 갖는다.   \n",
    "torchvision.transforms 모듈은 주로 사용하는 몇 가지 변형을 제공한다.  \n",
    "\n",
    "FashionMNIST 특징은 PIL 이미지 형식이며, 정답은 정수이다. 학습을 하려면 정규화된 텐서 형태의 특징과 원핫으로 부호화된 텐서 형태의 정답이 필요하다.  \n",
    "이러한 변형을 하기 위해 ToTensor와 Lambda를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "413ef626-73de-47d8-a822-f284d94d4d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "ds = datasets.FashionMNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = ToTensor(),\n",
    "    target_transform = Lambda(lambda y : torch.zeros(10, dtype = torch.float).scatter_(0, torch.tensor(y), value = 1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c98c68-fb28-481c-acc7-bea39c2c901c",
   "metadata": {},
   "source": [
    "## ToTensor()\n",
    "ToTensor는 PIL image나 넘파이 ndarray를 FloatTensor로 변환하고,  \n",
    "이미지의 픽셀의 크기 값을 [0.,1.] 범위로 비례하여 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3406a838-1421-49e5-baab-22ad7e79104e",
   "metadata": {},
   "source": [
    "## Lambda 변형(Transform)\n",
    "Lambda 변형은 사용자 정의 람다함수를 적용한다. \n",
    "여기에서는 정수를 원핫으로 부호화된 텐서로 바꾸는 함수를 정의한다.\n",
    "이 함수는 먼저(데이터셋 정답의 개수인) 크기 10짜리 영 텐서를 만들고,  \n",
    "scatter_를 호출하여 주어진 정답 y에 해당하는 인덱스에 value =1 을 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d224254d-115f-484d-b140-8ffcd57c4e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_transform = Lambda(lambda y: torch.zeros(\n",
    "    10, dtype = torch.float).scatter_(dim = 0, index = torch.tensor(y), value = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1b2696-e70a-46c3-8613-c6ff10312af0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
