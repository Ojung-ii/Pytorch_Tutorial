{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcfad4cd-7cbe-4960-b094-45077e938ab2",
   "metadata": {},
   "source": [
    "# 신경망 모델 구성하기\n",
    "신경망은 데이터에 대한 연산을 수행하는 계층 / 모듈로 구성되어 있다.  \n",
    "torch.nn 네임스페이스는 신경망을 구성하는데 필요한 모든 구성 요소를 제공합니다.  \n",
    "Pytorch의 모든 모듈은 nn.Module의 하위 클래스이다.  \n",
    "신경망은 다른 모듈로 구성된 모듈이다. 이러한 중첩된 구조는 복잡한 아키텍처를 쉽게 구축하고 관리할 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6e8dd1b-fd68-4c47-b2da-6ac282e7916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039dd7fd-f4b5-43a1-819d-4836893ab68d",
   "metadata": {},
   "source": [
    "## 학습을 위한 장치 얻기\n",
    "가능한 경우 GPU 또는 MPS와 같은 하드웨어 가속기에서 모델을 학습하려고 한다.  \n",
    "torch.cuda 또는 torch.backends.mps가 사용 가능한지 확인해보고, 그렇지 않으면 CPU를 계속 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a482c9ec-fe4c-4d9a-9779-19e3977f7a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    'cuda' \n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf4b925-2bf8-4c6b-8529-3bbda5587158",
   "metadata": {},
   "source": [
    "## 클래스 정의하기\n",
    "신경망 모델을 nn.Module 의 하위클래스로 정의하고, __init__에서 신경망 계층들을 초기화한다.  \n",
    "nn.Module 을 상속받은 모델 클래스는 forward 메소드에 입력 데이터에 연산들을 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f395aeba-75af-4ad1-b167-1915a77f28f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "        nn.Linear(28*28, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512,10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a51f50-529e-4ec6-9800-0f7f54d78cd9",
   "metadata": {},
   "source": [
    "NeuralNetwork의 인스턴스를 생성하고 이를 device로 이동한 뒤, 구조를 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f86760e4-65a6-499b-b518-f8472053dd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4486ac1-01b3-4628-a6b5-ec3d10388bb3",
   "metadata": {},
   "source": [
    "모델을 사용하기 위해 입력 데이터를 전달한다. 이는 일부 백그라운드 연산들과 함께 모델의 forward를 실행.  model.forward()를 직접 호출하지 마세요!\n",
    "\n",
    "모델에 입력을 전달하는 호출하면 2차원 텐서를 반환한다. 2차원 텐서의 dim = 0은 각 분류에 대해 원시 예측값 10개가, dim = 1에는 각 출력의 개별값들이 해당한다. 원시 예측값은 nn.Softmax 모듈의 인스턴스에 통과시켜 예측확률을 얻는다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0f2dfe5-90ae-4c66-aeb0-62248d8608d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([-9223372036854775808], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1,28,28, device = device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim = 1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f'Predicted class: {y_pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91524c3b-91be-4c99-9676-d80820ffef1d",
   "metadata": {},
   "source": [
    "# 모델 계층(Layer)\n",
    "FashionMNIST 모델의 계층을 살펴보자. 이를 설명하기 위해, 28x28 크기의 이미지 3개로 구성된 미니배치를 가져와, 신경망을 통과할 때 어떤 일이 발생하는지 알아보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be509041-e575-4b6a-b86d-53969f874565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc469438-9083-455a-9ee0-4375377d0fee",
   "metadata": {},
   "source": [
    "## nn.Flatten\n",
    "nn.Flatten 계층을 초기화하여 각 28x28의 2D 이미지를 784픽셀 값을 갖는 연속된 배열로 반환한다. \n",
    "(dim = 0의 미니배치 차원은 유지된다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ee7a3d6-1494-4ced-90e4-9e90c8f1e672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9482320-d376-43d1-8c43-4741ed672a28",
   "metadata": {},
   "source": [
    "## nn.Linear\n",
    "선형 계층은 저장도니 가중치와 편향을 사용하여 입력에 선형 변환을 적용하는 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c32d426d-2d46-42bc-bf3b-93c19eb7929e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features = 28*28, out_features =20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bddbbd-7b71-44c9-90ad-c173a1d5a012",
   "metadata": {},
   "source": [
    "## nn.ReLU\n",
    "비선형 활성화는 모델의 입력과 출력 사이에 복잡한 관계를 만든다.   \n",
    "비선형 활성화는 선형 변환 후에 적용되어 비선형성을 도입하고, 신경망이 다야한 현상을 학습할 수 있도록 돕는다.\n",
    "\n",
    "이 모델에서는 nn.ReLU를 선형 계층들 사이에 사용하지만, 모델을 만들 때는 비선형성을 가진 다른 활성화를 도입할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bdb9d2e-a1c8-4f35-9de7-e8b4545d3c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU : tensor([[0.1310, 0.0000, 0.1783, 0.0000, 0.5375, 0.0000, 0.0000, 0.5331, 0.0740,\n",
      "         0.0000, 0.0157, 0.0915, 0.1489, 0.1417, 0.0178, 0.0000, 0.0000, 0.0000,\n",
      "         0.1858, 0.1405],\n",
      "        [0.1612, 0.0484, 0.0000, 0.2558, 0.6876, 0.0000, 0.0107, 0.2107, 0.0000,\n",
      "         0.0722, 0.0000, 0.1861, 0.0000, 0.0454, 0.0172, 0.0000, 0.0000, 0.0000,\n",
      "         0.4417, 0.0009],\n",
      "        [0.0000, 0.1465, 0.1976, 0.0000, 0.0923, 0.0000, 0.0000, 0.1230, 0.0000,\n",
      "         0.0000, 0.0000, 0.0803, 0.0000, 0.0846, 0.1642, 0.0000, 0.0000, 0.0000,\n",
      "         0.1930, 0.3775]], grad_fn=<ReluBackward0>)\n",
      "\n",
      "\n",
      "After ReLU : tensor([[0.1310, 0.0000, 0.1783, 0.0000, 0.5375, 0.0000, 0.0000, 0.5331, 0.0740,\n",
      "         0.0000, 0.0157, 0.0915, 0.1489, 0.1417, 0.0178, 0.0000, 0.0000, 0.0000,\n",
      "         0.1858, 0.1405],\n",
      "        [0.1612, 0.0484, 0.0000, 0.2558, 0.6876, 0.0000, 0.0107, 0.2107, 0.0000,\n",
      "         0.0722, 0.0000, 0.1861, 0.0000, 0.0454, 0.0172, 0.0000, 0.0000, 0.0000,\n",
      "         0.4417, 0.0009],\n",
      "        [0.0000, 0.1465, 0.1976, 0.0000, 0.0923, 0.0000, 0.0000, 0.1230, 0.0000,\n",
      "         0.0000, 0.0000, 0.0803, 0.0000, 0.0846, 0.1642, 0.0000, 0.0000, 0.0000,\n",
      "         0.1930, 0.3775]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f'Before ReLU : {hidden1}\\n\\n')\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f'After ReLU : {hidden1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4978fe-c711-40b5-9fa9-6f69890fc8e7",
   "metadata": {},
   "source": [
    "## nn.Sequential\n",
    "nn.Sequential은 순서를 갖는 모듈의 컨테이너이다. 데이터는 정의된 것과 같은 순서로 모든 모듈들을 통해 전달된다. 순차 컨테이너를 사용하여 아래의 seq_models 와 같은 신경망을 빠르게 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45b30181-e70e-462e-9e9a-928765fa4251",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20,10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4368a831-b2e4-42f8-ad94-900e08a5ba5c",
   "metadata": {},
   "source": [
    "## nn.Softmax\n",
    "신경망의 마지막 선형 계층은 nn.Softmax 모듈에 전달된 ([-infinity, infinity] 범위의 원시 값인) logits를 반환한다. logits는 모델의 각 분류에 대한 예측 확률을 나타내도록 [0,1] 범위로 비례하여 조정된다. dim 매개변수는 값의 합이 1이 되는 차원을 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29d1c735-0cae-4b52-b94c-9679cd298204",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8641a04-e9f5-42cb-a5a2-3f394ffbbd1c",
   "metadata": {},
   "source": [
    "## 모델 매개변수\n",
    "신경망 내부의 많은 계층들은 매개변수화 된다. 즉, 학습 중에 최적화되는 가중치와 편향을 연결지어진다. nn.Module을 상속하면 모델 객체 내부의 모든 필드들이 자동을 추적되며, 모델의 parameter() named_parameter() 메소드로 모든 매개변수의 크기와 값을 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02bb9d5e-517b-4dfb-a32a-6bccd4a8a37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module structure : NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer : linear_relu_stack.0.weight | Size : torch.Size([512, 784]) | Values : tensor([[ 0.0297, -0.0124, -0.0224,  ..., -0.0187, -0.0170, -0.0049],\n",
      "        [-0.0351, -0.0277, -0.0118,  ...,  0.0033, -0.0206,  0.0035]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>)\n",
      "\n",
      "Layer : linear_relu_stack.0.bias | Size : torch.Size([512]) | Values : tensor([-0.0168,  0.0293], device='mps:0', grad_fn=<SliceBackward0>)\n",
      "\n",
      "Layer : linear_relu_stack.2.weight | Size : torch.Size([512, 512]) | Values : tensor([[ 0.0060, -0.0081, -0.0080,  ..., -0.0191, -0.0170,  0.0172],\n",
      "        [ 0.0200,  0.0339, -0.0143,  ...,  0.0320, -0.0301, -0.0099]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>)\n",
      "\n",
      "Layer : linear_relu_stack.2.bias | Size : torch.Size([512]) | Values : tensor([-0.0246,  0.0023], device='mps:0', grad_fn=<SliceBackward0>)\n",
      "\n",
      "Layer : linear_relu_stack.4.weight | Size : torch.Size([10, 512]) | Values : tensor([[ 0.0287, -0.0234,  0.0068,  ..., -0.0091,  0.0070, -0.0372],\n",
      "        [ 0.0230,  0.0020,  0.0327,  ..., -0.0209, -0.0372,  0.0198]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>)\n",
      "\n",
      "Layer : linear_relu_stack.4.bias | Size : torch.Size([10]) | Values : tensor([-0.0070,  0.0214], device='mps:0', grad_fn=<SliceBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Module structure : {model}\\n\\n')\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f'Layer : {name} | Size : {param.size()} | Values : {param[:2]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90b890d4-b076-44d5-9a07-10859737662f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1., 1., 1.],\n",
       "        [1., 4., 1., 1.],\n",
       "        [1., 1., 4., 1.],\n",
       "        [1., 1., 1., 4.],\n",
       "        [1., 1., 1., 1.]], grad_fn=<TBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.eye(4, 5, requires_grad=True)\n",
    "out = (inp+1).pow(2).t()\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f600db6-8fff-4616-89a6-c6b88c57fed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
